{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07fc871",
   "metadata": {},
   "source": [
    "## 1. Install dependences and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f842c-7290-4855-a7fc-0680bbbaacc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1cc9ee-8025-42a2-a609-2e2dbb9e8066",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a09ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imghdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45356a9-01e4-468e-83fb-9075e7df8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "\n",
    "# Change to the directory with your dataset\n",
    "%cd /content/drive/My Drive/ML_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fcd8e-51ca-4067-bcd5-f78395c471eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c30cc7-4a8b-4c38-ac2f-91cffcf2c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OutOfMemory error | I do not have a GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c8c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.image_dataset_from_directory??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fab4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the train and test directories\n",
    "train_dir = 'data\\\\train'\n",
    "test_dir = 'data\\\\test'\n",
    "\n",
    "# with keras.utils we do not have to code the labels, and it preprocesses\n",
    "train = tf.keras.utils.image_dataset_from_directory(train_dir, \n",
    "                                                    color_mode = 'grayscale')\n",
    "test = tf.keras.utils.image_dataset_from_directory(test_dir, \n",
    "                                                   color_mode = 'grayscale')\n",
    "\n",
    "# train and test are NOT preloaded, they are generators.\n",
    "# we first convert into a numpy iterator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7936da-44b6-4f85-b9ce-a6292a03902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with iterators we can access the data pipeline\n",
    "train_iterator = train.as_numpy_iterator()\n",
    "test_iterator = test.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3aaa7b-70c5-4e92-ae25-1ae6c5937537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets another batch from the iterator\n",
    "train_batch = train_iterator.next()\n",
    "# the batches have 2 variables, the first one is the image representation, the second is the label\n",
    "print(len(train_batch))\n",
    "train_batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb8f4d9-6796-423b-89f7-3728edd55c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c8bb4a-c991-41f5-934c-85c9e513cbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c23b1be-bb32-4efa-b805-73eb65dd3e9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Debug, why with the cell above Jupyter crashes?\n",
    "print(\"Inspecting images and labels:\")\n",
    "for idx, img in enumerate(train_batch[0][:4]):\n",
    "    print(f\"Image {idx} - shape: {img.shape}, dtype: {img.dtype}, min: {img.min()}, max: {img.max()}\")\n",
    "    \n",
    "print(\"Labels:\", train_batch[1][:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663a4bb-e1f6-4c1f-93c9-71775d01727c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7934e3c7",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "- Resize all images -> already done\n",
    "- Bring everything to greyscale -> already done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c65b57-4b53-42df-8562-d57eb61ce1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of each image\n",
    "print(train_batch[0].shape)\n",
    "\n",
    "print(train_batch[0].min())\n",
    "print(train_batch[0].max()) # we want values as small as possible -> /255\n",
    "# this makes optimization more efficient -> we need to scale values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14ba8a-90e8-4be1-a1ee-f7348e6f5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we implement the data transformation in the pipeline\n",
    "# x represent images, y labels\n",
    "train = train.map(lambda x,y: (x/255,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc53bee-91be-4662-bd8e-072eb6b65fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.as_numpy_iterator().next() # since we have shuffling data changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23ac68-5ac4-4945-843c-75bea59af101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the values of the images\n",
    "print(f\"Min value of scaled images: {train.as_numpy_iterator().next()[0].min()}\")\n",
    "print(f\"Max value of scaled images: {train.as_numpy_iterator().next()[0].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8989d5-14c0-4b34-bfef-296dde4d8d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is 0? What is 1? This makes jupyter crash\n",
    "fig, ax = plt.subplots(ncols = 4, figsize = (20,20))\n",
    "for idx, img in enumerate(train_batch[0][:4]):\n",
    "    ax[idx].imshow(img)\n",
    "    ax[idx].title.set_text(train_batch[1][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d6093-a482-4fa4-b4f1-8dd0382cb6d0",
   "metadata": {},
   "source": [
    "## Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33fc38-d771-41f6-8925-0dbabe606257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
