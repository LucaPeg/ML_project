{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e07fc871",
      "metadata": {
        "id": "e07fc871"
      },
      "source": [
        "## 1. Install dependences and load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d42a09ef",
      "metadata": {
        "id": "d42a09ef"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import imghdr\n",
        "import matplotlib\n",
        "from PIL import Image\n",
        "import random\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e45356a9-01e4-468e-83fb-9075e7df8014",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e45356a9-01e4-468e-83fb-9075e7df8014",
        "outputId": "2a2e43ff-659b-408a-866a-3b928d3a6d59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# connect to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the date with pickle. We serialized these objects with pickle in the \"data_prep\" notebook.\n",
        "I divided the two notebooks so that I can use 'run all' more convenientely here."
      ],
      "metadata": {
        "id": "eXz0lYaZy8eA"
      },
      "id": "eXz0lYaZy8eA"
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_in = open( \"/content/drive/MyDrive/ml_project/\"+\"img_train.pickle\",\"rb\")\n",
        "img_train = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open( \"/content/drive/MyDrive/ml_project/\"+\"label_train.pickle\",\"rb\")\n",
        "label_train = pickle.load(pickle_in)\n",
        "\n",
        "\n",
        "pickle_in = open( \"/content/drive/MyDrive/ml_project/\"+\"img_test.pickle\",\"rb\")\n",
        "img_test = pickle.load(pickle_in)\n",
        "\n",
        "pickle_in = open( \"/content/drive/MyDrive/ml_project/\"+\"label_test.pickle\",\"rb\")\n",
        "label_test = pickle.load(pickle_in)\n"
      ],
      "metadata": {
        "id": "L03jBaADytLS",
        "outputId": "d141a1bd-f556-4297-9029-5206678d0948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "id": "L03jBaADytLS",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ml_project/img_train.pickle'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-624d38dc465a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/ml_project/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"img_train.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimg_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpickle_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/ml_project/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"label_train.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabel_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ml_project/img_train.pickle'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09c30cc7-4a8b-4c38-ac2f-91cffcf2c34b",
      "metadata": {
        "id": "09c30cc7-4a8b-4c38-ac2f-91cffcf2c34b"
      },
      "outputs": [],
      "source": [
        "# Avoid OutOfMemory error | I do not have a GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n",
        "print(gpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Check and pre-process data"
      ],
      "metadata": {
        "id": "gb11vCQ1rkxA"
      },
      "id": "gb11vCQ1rkxA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99fab4b9",
      "metadata": {
        "id": "99fab4b9"
      },
      "outputs": [],
      "source": [
        "# Define the paths to the train and test directories\n",
        "train_dir = '/content/train'\n",
        "test_dir = '/content/test'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We visualize the images to get an idea of their structure / MUFFINS\n",
        "images=[]\n",
        "f, axarr = plt.subplots(2,2, figsize=(10,10))\n",
        "im_index=0\n",
        "\n",
        "for row in range(2):\n",
        "    for column in range(2):\n",
        "        path=os.path.join(train_dir,'muffin')\n",
        "        images.append(cv2.imread(os.path.join(path,os.listdir(path)[im_index])))\n",
        "        axarr[row,column].imshow(cv2.cvtColor(images[im_index], cv2.COLOR_BGR2RGB))\n",
        "        im_index+=1\n",
        "        axarr[row,column].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VT-3A1qfcT9P"
      },
      "id": "VT-3A1qfcT9P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We visualize the images to get an idea of their structure / CHIHUAHUAS\n",
        "images=[]\n",
        "f, axarr = plt.subplots(2,2, figsize=(10,10))\n",
        "im_index=0\n",
        "\n",
        "for row in range(2):\n",
        "    for column in range(2):\n",
        "        path=os.path.join(train_dir,'chihuahua')\n",
        "        images.append(cv2.imread(os.path.join(path,os.listdir(path)[im_index])))\n",
        "        axarr[row,column].imshow(cv2.cvtColor(images[im_index], cv2.COLOR_BGR2RGB))\n",
        "        im_index+=1\n",
        "        axarr[row,column].axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z3pWLOHqeTNW"
      },
      "id": "Z3pWLOHqeTNW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "501d6093-a482-4fa4-b4f1-8dd0382cb6d0",
      "metadata": {
        "id": "501d6093-a482-4fa4-b4f1-8dd0382cb6d0"
      },
      "source": [
        "## Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d33fc38-d771-41f6-8925-0dbabe606257",
      "metadata": {
        "id": "5d33fc38-d771-41f6-8925-0dbabe606257"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential # good with 1 input 1 output\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the first model\n",
        "model0 = Sequential()\n",
        "\n",
        "# First layer must be input layer or have an input\n",
        "model0.add(Conv2D(16, (3, 3), 1, activation='relu', input_shape=(150, 150, 1)))  # Change channels from 1 to 3 if using RGB instead of grayscale\n",
        "# 16 is the number of filters, each filter is 3x3 pixels, 1 is the stride\n",
        "model0.add(MaxPooling2D())\n",
        "# This takes the maximum value after the ReLU and returns it\n",
        "# Check MaxPooling2D?? for each 2x2 region (pool) takes the highest value\n",
        "\n",
        "model0.add(Conv2D(32, (3, 3), 1, activation='relu'))  # Now 32 filters\n",
        "model0.add(MaxPooling2D())\n",
        "\n",
        "model0.add(Conv2D(16, (3, 3), 1, activation='relu'))\n",
        "model0.add(MaxPooling2D())\n",
        "\n",
        "model0.add(Flatten())\n",
        "# When we apply the conv layer, the filters are going to be the last channel.\n",
        "# We condense the length and width, then the number of filters will form the\n",
        "# channel value. When we pass values to the dense layer, we don't want multiple\n",
        "# values, but we want to 'flatten' them into a single value (thus the Flatten layer).\n",
        "\n",
        "# Dense layers are fully connected layers\n",
        "model0.add(Dense(256, activation='relu'))  # 256 values as output\n",
        "model0.add(Dense(1, activation='sigmoid'))  # 1 output only, due to sigmoid\n",
        "\n",
        "model0.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
        "# we use binary cross entropy since it is a classification problem.\n",
        "#tf.optimizers. to get all the optimizers\n",
        "\n",
        "model0.summary()"
      ],
      "metadata": {
        "id": "fRdkONoZId37"
      },
      "id": "fRdkONoZId37",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "pimUg9IaPS8M"
      },
      "id": "pimUg9IaPS8M"
    },
    {
      "cell_type": "code",
      "source": [
        "#.fit method -> training component\n",
        "#.predict -> when we make the predictions\n",
        "hist0 = model0.fit(img_train,\n",
        "                   label_train,\n",
        "                   batch_size = 32,\n",
        "                   epochs=20,\n",
        "                   validation_split = 0.15\n",
        "                   )\n",
        "\n",
        "# This takes too long.."
      ],
      "metadata": {
        "id": "rFT4vjrzP600"
      },
      "id": "rFT4vjrzP600",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Results of Model\n"
      ],
      "metadata": {
        "id": "_QEVPVV8z0Di"
      },
      "id": "_QEVPVV8z0Di"
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_accuracy(histo):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Plot loss\n",
        "    axs[0].plot(histo.history['loss'], color='teal', label='loss')\n",
        "    axs[0].plot(histo.history['val_loss'], color='orange', label='val_loss')\n",
        "    axs[0].set_title('Loss', fontsize=20)\n",
        "    axs[0].legend(loc='upper left')\n",
        "\n",
        "    # Plot accuracy\n",
        "    axs[1].plot(histo.history['accuracy'], color='teal', label='accuracy')\n",
        "    axs[1].plot(histo.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "    axs[1].set_title('Accuracy', fontsize=20)\n",
        "    axs[1].legend(loc='upper left')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "N3H-rWBsz2SD"
      },
      "id": "N3H-rWBsz2SD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_accuracy(hist0)"
      ],
      "metadata": {
        "id": "kHfE2qTI0Y19"
      },
      "id": "kHfE2qTI0Y19",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The following two blocks of code should be unnecessary now\n",
        "fig = plt.figure()\n",
        "plt.plot(hist0.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist0.history['val_loss'],color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YEE2JPQX-3zT"
      },
      "id": "YEE2JPQX-3zT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], color='orange',label='val_accuracy')\n",
        "fig.suptitle('Accuracy', fontsize=20)\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OxYou6JvAEkM"
      },
      "id": "OxYou6JvAEkM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Refine the model\n",
        "The main issue is overfitting, we can try to solve the issue by adding Dropout or a BatchNormalization Layer. After doing this we move to the next model.\n",
        "\n",
        "The dropout layer is applied on the dense layer before the ouput, using a value of p=0.5, following the methodology of Hinton(2012) (the paper where dropout was initially proposed.\n",
        "\n",
        "However, according to (more) recent research (Park and Kwak, Analysis on the Dropout Effect in Convolutional Neural Networks), applying a lower level dropout (p=0.1) to convolutional layers can be beneficial.\n",
        "\n",
        "However, according to some: \"We must not use dropout layer after convolutional layer as we slide the filter over the width and height of the input image we produce a 2-dimensional activation map that gives the responses of that filter at every spatial position. So as dropout layer neutralizes (makes it zero) random neurons there are chances of loosing very important feature in an image in our training process.\" Pooja Sonkar (https://stats.stackexchange.com/users/215170/pooja-sonkar), Where should I place dropout layers in a neural network?, URL (version: 2018-10-05): https://stats.stackexchange.com/q/370325"
      ],
      "metadata": {
        "id": "ozumFajG7daw"
      },
      "id": "ozumFajG7daw"
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the first model with dropout\n",
        "model0d = Sequential()\n",
        "\n",
        "model0d.add(Conv2D(16, (3, 3), 1, activation='relu', input_shape=(150, 150, 1)))  # Change channels from 1 to 3 if using RGB instead of grayscale\n",
        "model0d.add(MaxPooling2D())\n",
        "\n",
        "model0d.add(Conv2D(32, (3, 3), 1, activation='relu'))\n",
        "model0d.add(MaxPooling2D())\n",
        "\n",
        "model0d.add(Conv2D(16, (3, 3), 1, activation='relu'))\n",
        "model0d.add(MaxPooling2D())\n",
        "\n",
        "model0d.add(Flatten())\n",
        "\n",
        "model0d.add(Dense(256, activation='relu'))\n",
        "model0d.add(Dropout(0.5)) # we add dropout to reduce overfitting\n",
        "model0d.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model0d.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "model0d.summary()"
      ],
      "metadata": {
        "id": "RMhTdLgCGN0U"
      },
      "id": "RMhTdLgCGN0U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the history of the model with dropout\n",
        "\n",
        "hist0d = model0d.fit(img_train,\n",
        "                   label_train,\n",
        "                   batch_size = 32,\n",
        "                   epochs=20,\n",
        "                   validation_split = 0.15\n",
        "                   )\n",
        "\n",
        "plot_loss_accuracy(hist0d)"
      ],
      "metadata": {
        "id": "-QCkRS6OIACV"
      },
      "id": "-QCkRS6OIACV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add L2 regularization\n",
        "L2 regularization requires the addition of an extra term to the loss function of the network."
      ],
      "metadata": {
        "id": "3W9bzZc-3rsi"
      },
      "id": "3W9bzZc-3rsi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate Performance"
      ],
      "metadata": {
        "id": "qXxuIXkDRaWj"
      },
      "id": "qXxuIXkDRaWj"
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss decreases steadily over time. However, while initially the validation loss decreases, around the 6th epoch it starts to increaase. This pattern possibly conveys overfitting of our algorithm. To improve this result we may need to apply regularization."
      ],
      "metadata": {
        "id": "iNLBQulj_bwV"
      },
      "id": "iNLBQulj_bwV"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ],
      "metadata": {
        "id": "iqyay1EFRfxk"
      },
      "id": "iqyay1EFRfxk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To use the metrics we need to establish instances of them\n",
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = BinaryAccuracy()"
      ],
      "metadata": {
        "id": "PSYu_zhBQbK-"
      },
      "id": "PSYu_zhBQbK-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaled_iterator_test\n",
        "len(test)"
      ],
      "metadata": {
        "id": "GLQGp9BlBrSH"
      },
      "id": "GLQGp9BlBrSH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in scaled_iterator_test: # is scaled_iterator_test correct?\n",
        "  X, y = batch                     # or test_batch = scaled_iterator_test.next()\n",
        "  yhat = model.predict(X)\n",
        "  pre.update_state(y, yhat)\n",
        "  re.update_state(y, yhat)\n",
        "  acc.update_state(y, yhat)"
      ],
      "metadata": {
        "id": "qNE-624ER4YA"
      },
      "id": "qNE-624ER4YA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Precision: {pre.result():.2f}, Recall: {re.result():.2f}, Accuracy: {acc.result():.2f}\")"
      ],
      "metadata": {
        "id": "i8g0e3eOCLuV"
      },
      "id": "i8g0e3eOCLuV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second model\n",
        "A second fancier model must be designed. How do I do it? I don't know."
      ],
      "metadata": {
        "id": "NYl6Sey-2Y61"
      },
      "id": "NYl6Sey-2Y61"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rt5iu2UM2hI9"
      },
      "id": "Rt5iu2UM2hI9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model\n",
        "Maybe this can be done after we get the best model, and only for that model\n"
      ],
      "metadata": {
        "id": "aod6egWnEoL6"
      },
      "id": "aod6egWnEoL6"
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "1Djc_AwqEq6Y"
      },
      "id": "1Djc_AwqEq6Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(os.path.join('models','model1.h5'))\n",
        "# h5 is a serialization format, like .zip"
      ],
      "metadata": {
        "id": "hwLBa9H7ExkE"
      },
      "id": "hwLBa9H7ExkE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# \"import\" the model\n",
        "new_model = load_model(os.path.join('models','model1.h5'))"
      ],
      "metadata": {
        "id": "WJkGD58KFKZz"
      },
      "id": "WJkGD58KFKZz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2dRUEyFA30U9"
      },
      "id": "2dRUEyFA30U9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (ml)",
      "language": "python",
      "name": "ml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}